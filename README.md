# Sphere_Spark
用spark 进行数据的etl
数据源目前有mongodb 和mysql db
初版代码实现了 mongodb 的连接和一个简单的硬变成的数据抽取

以下有待实现：
1，mysql 的连接
2，将db源的各个信息，uri，项目，schema等参数化
3，spark conf 的设置
4，hdfs 的pq存储设置

目前就想到这些
